{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping project - Complete Machine Learning Notebook\n",
    "### **Léo RINGEISSEN & Santiago MARTIN - DIA 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook follows the work we did in the previous API and Webscraping notebook :**\n",
    "\n",
    "In our last submission, we demonstrated how we accessed an SNCF dataset API and webscraped TripAdvisor reviews to produce a dataset containing reviews and emissions data for a variety of travel destinations available by train from Paris.\n",
    "\n",
    "The text underneath details the adjustments in scope made during the process of producing our dataset.\n",
    "\n",
    "**Adjustments to the project scope :**\n",
    "\n",
    "We've learned over the course of this work that a typical method used by companies to prevent bots from illegally scraping their web pages is to deliberately complicate the repetitive tasks a bot would do. \n",
    "\n",
    "An example of this is having inconsistent page scrolling, where going to page 2 from page 3 won't be the same as if you'd gone from page 1. Another example is not having simple logic between the URLs of different pages. There are also dynamic elements like text translations that do not get retrieved in the initial soup provided by Selenium.\n",
    "\n",
    "We initially thought that these were merely poor implementations from TripAdvisor, but we now understand that these inefficiencies are deliberate to prevent any automated web scraping processes from taking place, we can therefore not bypass most of these issues without partnering with or paying TripAdvisor to access their data.\n",
    "\n",
    "As a result of these limitations, as well as data limitations on the end of the contents of the SNCF API, we've reduced the scope of our project to only trips by train whose origin is Paris and whose destination has a page with sufficient reviews in French on TripAdvisor. In addition, many destinations didn't have review pages at all, so we took the reviews of that destination's most iconic landmark, which would serve as an adequate substitution.\n",
    "\n",
    "**Data quality and project scalability :**\n",
    "\n",
    "With these adjustments to the project scope, we end up working with around a third (36) of the itineraries accessible with the API (119), and half of the itineraries whose origin is Paris (75), which still leaves with ample room to make fun and ecological travel recommendations based on traveler preferences and ecological goals, which was the objective we set out to achieve with this project.\n",
    "\n",
    "Since we couldn't scroll through review pages without being thrown out for bot detection, we resolved the issue by manually selecting the URLs to the first and second review pages (if a second review page is even available). We recognize that this solution would not be scalable for a project with bigger scope, as with more desintations and review pages it would require a lot of manual labor to copy all of the URLs by hand. Fortunately, for the goals of this project which are to learn to web scrape data and utilize it for Machine Learning applications, this is not a concern and we can still move forward with our project.\n",
    "\n",
    "Using automated google engine searches to automatically find URLs was not a viable option too, as the google search engine results are also made difficult to use via a bot, and we still would have to manually monitor the quality of the first urls yielded by our bot, so it would need more complex and powerful libraries than selenium to be crate a more scalable solution.\n",
    "\n",
    "**Final CSV generation :**\n",
    "\n",
    "By the end of the dataset production notebook we generate an aggregated and a non-aggregated CSV file containing our API and web scraped data. The columns are origin, destination, links for first and second review pages, distance between origin and destination, train trip carbon emissions, the scraped URL (only in the non-aggregated file), the review title (concatenated in the aggregated file), the review content (concatenated in the aggregated file), and the review rating (averaged in the aggregated file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and exploring our produced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 9)\n",
      "origine             object\n",
      "destination         object\n",
      "page1_link          object\n",
      "page2_link          object\n",
      "distance           float64\n",
      "train_emissions    float64\n",
      "titles              object\n",
      "reviews             object\n",
      "average_rating     float64\n",
      "dtype: object\n",
      "origine             0\n",
      "destination         0\n",
      "page1_link          0\n",
      "page2_link         22\n",
      "distance            0\n",
      "train_emissions     0\n",
      "titles              0\n",
      "reviews             0\n",
      "average_rating      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origine</th>\n",
       "      <th>destination</th>\n",
       "      <th>page1_link</th>\n",
       "      <th>page2_link</th>\n",
       "      <th>distance</th>\n",
       "      <th>train_emissions</th>\n",
       "      <th>titles</th>\n",
       "      <th>reviews</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>545.00</td>\n",
       "      <td>1.580500</td>\n",
       "      <td>“Annecyyyy...!!! Quand tu nous tiens..!!!” || ...</td>\n",
       "      <td>Vtt sur le Semnoz, pédalo sur le lac, promenad...</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "      <td>Zuerich HB</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>614.00</td>\n",
       "      <td>2.087600</td>\n",
       "      <td>“Zurich le temps d'un weekend”</td>\n",
       "      <td>Une ville riche et agréable ou le centre histo...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris Saint-Lazare</td>\n",
       "      <td>Rouen Rive Droite</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>139.00</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>“la cathédrale est de plus en plus belle!” || ...</td>\n",
       "      <td>il faisait un temps moyen,mais le poissonnier ...</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paris Montparnasse</td>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460.00</td>\n",
       "      <td>1.334000</td>\n",
       "      <td>la mentalité à revoir || Charmant || Plaisant ...</td>\n",
       "      <td>les employés dans les magasins au centre de la...</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paris Gare de Lyon</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>https://www.tripadvisor.fr/ShowUserReviews-g18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>556.09</td>\n",
       "      <td>1.612661</td>\n",
       "      <td>“Ma ville” || “ville etudiante et sky”</td>\n",
       "      <td>Au coeur des montagnes, hiver comme été, Greno...</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              origine        destination  \\\n",
       "0  Paris Gare de Lyon             Annecy   \n",
       "1  Paris Gare de Lyon         Zuerich HB   \n",
       "2  Paris Saint-Lazare  Rouen Rive Droite   \n",
       "3  Paris Montparnasse        La Rochelle   \n",
       "4  Paris Gare de Lyon           Grenoble   \n",
       "\n",
       "                                          page1_link  \\\n",
       "0  https://www.tripadvisor.fr/ShowUserReviews-g18...   \n",
       "1  https://www.tripadvisor.fr/ShowUserReviews-g18...   \n",
       "2  https://www.tripadvisor.fr/ShowUserReviews-g18...   \n",
       "3  https://www.tripadvisor.fr/ShowUserReviews-g18...   \n",
       "4  https://www.tripadvisor.fr/ShowUserReviews-g18...   \n",
       "\n",
       "                                          page2_link  distance  \\\n",
       "0  https://www.tripadvisor.fr/ShowUserReviews-g18...    545.00   \n",
       "1                                                NaN    614.00   \n",
       "2  https://www.tripadvisor.fr/ShowUserReviews-g18...    139.00   \n",
       "3                                                NaN    460.00   \n",
       "4                                                NaN    556.09   \n",
       "\n",
       "   train_emissions                                             titles  \\\n",
       "0         1.580500  “Annecyyyy...!!! Quand tu nous tiens..!!!” || ...   \n",
       "1         2.087600                     “Zurich le temps d'un weekend”   \n",
       "2         3.391600  “la cathédrale est de plus en plus belle!” || ...   \n",
       "3         1.334000  la mentalité à revoir || Charmant || Plaisant ...   \n",
       "4         1.612661             “Ma ville” || “ville etudiante et sky”   \n",
       "\n",
       "                                             reviews  average_rating  \n",
       "0  Vtt sur le Semnoz, pédalo sur le lac, promenad...        4.400000  \n",
       "1  Une ville riche et agréable ou le centre histo...        5.000000  \n",
       "2  il faisait un temps moyen,mais le poissonnier ...        4.142857  \n",
       "3  les employés dans les magasins au centre de la...        4.333333  \n",
       "4  Au coeur des montagnes, hiver comme été, Greno...        4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg_df = pd.read_csv('aggregated_emissions_and_reviews.csv', sep=',')\n",
    "print(agg_df.shape)\n",
    "print(agg_df.dtypes)\n",
    "print(agg_df.isnull().sum())\n",
    "display(agg_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>distance</th>\n",
       "      <th>train_emissions</th>\n",
       "      <th>reviews</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annecy</td>\n",
       "      <td>545.00</td>\n",
       "      <td>1.580500</td>\n",
       "      <td>Vtt sur le Semnoz, pédalo sur le lac, promenad...</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zuerich HB</td>\n",
       "      <td>614.00</td>\n",
       "      <td>2.087600</td>\n",
       "      <td>Une ville riche et agréable ou le centre histo...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rouen Rive Droite</td>\n",
       "      <td>139.00</td>\n",
       "      <td>3.391600</td>\n",
       "      <td>il faisait un temps moyen,mais le poissonnier ...</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>460.00</td>\n",
       "      <td>1.334000</td>\n",
       "      <td>les employés dans les magasins au centre de la...</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grenoble</td>\n",
       "      <td>556.09</td>\n",
       "      <td>1.612661</td>\n",
       "      <td>Au coeur des montagnes, hiver comme été, Greno...</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         destination  distance  train_emissions  \\\n",
       "0             Annecy    545.00         1.580500   \n",
       "1         Zuerich HB    614.00         2.087600   \n",
       "2  Rouen Rive Droite    139.00         3.391600   \n",
       "3        La Rochelle    460.00         1.334000   \n",
       "4           Grenoble    556.09         1.612661   \n",
       "\n",
       "                                             reviews  average_rating  \n",
       "0  Vtt sur le Semnoz, pédalo sur le lac, promenad...        4.400000  \n",
       "1  Une ville riche et agréable ou le centre histo...        5.000000  \n",
       "2  il faisait un temps moyen,mais le poissonnier ...        4.142857  \n",
       "3  les employés dans les magasins au centre de la...        4.333333  \n",
       "4  Au coeur des montagnes, hiver comme été, Greno...        4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_df.drop(columns=['origine','page1_link', 'page2_link', 'titles'], inplace=True)\n",
    "display(agg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ringi_3xz04z7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ringi_3xz04z7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('french')) \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    regex_tokenizer = RegexpTokenizer('\\w\\w+')\n",
    "    text = regex_tokenizer.tokenize(text)\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vtt sur le Semnoz, pédalo sur le lac, promenade au bord de l'eau (superbe), l'ambiance de la vielle ville, pti resto super sympa... vraiment vraiment bien.... I love Annecy .... :-) || ville magnifique avec beaucoup de charme quand je vais a annecy j ai l impresssion de ne plus etre en francepas mal de choses a visiter notamment les gorges du fier non loin du centre balade en bateau sur le lac vieille ville typiqueet de tres bons restaurants mais aussi un joli marche le dimanche || Cet endroit est exceptionnel c'est d'ailleurs pour cela que plusieurs personnes traversent la France pour venir apprécier ce lac.Surtout agréable en été avec ses différentes animations dansantes ou artistiques.Lieu de convivialité pour aussi bien se balader, se poser sur la pelouse ou bien faire du pédalo l'été pour pouvoir explorer les différents horizons du lac et ses verdures. || Vous pouvez y trouver tout: les montagnes pour les randonnées, le lac avec de l'eau transparente pour se baigner et les rues anciennes, plein de bâtiments splendides..... || Destination idéale pour ceux qui aiment la baignade (eau du lac excellente et de tres bonne qualité), et la montagne (randonnées de tous niveaux).Cadre magnifique pour passer de tres bonnes vacances || Mai 2010, besoin de vacances et de dépaysement à petit prix urgent.Je propose donc à mon cher et tendre une virée romantique d'une semaine en Haute-Savoie. Je connaissais la région pour y être aller petite avec mes grand-parents,Nous partons donc sur Internet à la recherche d'un gîte à proximité d'Annecy. Après plusieurs jours de recherche nous trouvons une annonce sur \"le bon coin\", 250 € la semaine pour un P2 à Villard-Dessous(commune de Manigod).Arrivé sur place le spectacle nous laisse sans voix, le paysage est fabuleux, les montagnes face à nous enneigées.Nous avons profiter de notre semaine pour visiter Annecy, faire une ballade en bateau sur le Lac d'Annecy, aller dans une crémerie acheter le nécessaire pour la fondue savoyarde, visiter le Museùm de Genève (1 heure de route), voir le Lac Léman, visiter Yvoire qui est un magnifique petit village médiéval et piéton ! . Nous avons été voir la cascade du Rouget, dite la Reine des Alpes ou nous avons été arrosé d'embruns, visiter La gorge du pont du diable. et encore beaucoup de promenade et marché dans les villages au abord d'annecy. C'est une très belle région que nous conseillons à tous, petit et grand. Il y a de nombreuses activités pour tous les budgets, notre semain nous est revenu à environ 600 €, sorties, essence, péage, nourriture, location gîte compris.Une des choses que nous regrettons : ne pas avoir vu les marmottes !A noter aussi que si vous aimez visiter il faudra rouler. || cette ville m'enchante depuis une dizaine d'annéestant par son tourisme que par ses habitantscette ville est le reflet parfait de mes vacancesj'ai besoin d'y aller au moins une fois par an pour me resourcer || magnifique ville, des activités pour tous: proximité des stations de skis, activités nautiques l'été, une ville culturelle et historique magnifique, et un large choix de shopping!!Note spéciale pour le restaurant le \"20/Vins\" dans la vieille ville (passage Golliardi) , une formule originale pour déguster un large choix de bons vins et des plats diversifiés: du risotto au couscous en passant par la souris d'agneau ou bien un Mont d'or!! en prime, une déco moderne cosy et raffinée! || Ville très agréable.Pour une promenade sur le lac, il est possible de louer pédalos et autres bateaux avec ou sans moteur, malheureusement une entente sur les prix fausse totalement la concurrence.La ville a décidé de faire les poches des visiteurs grâce au tarif prohibitif des parkings municipaux.La ville s'avère tout à fait adaptée aux personnes âgées ou couples sans enfant(s). || une jolie ville,entourée de belles montagnes avec un lac magnifique.par contre une trés mauvaise mentalité,un trés mauvais accueille,avec un grand nombre de restaurants \"piege a touriste\" ,les prix sont carrement abusifs et les plats plus que médiocres .les habitants sont froid,sans intéréts,rustres et vraiment mal polies.ils n'ont aucun savoir vivre.ils ne sont absolument pas souriant(méme dans les commerces!).je n'y remettrais plus jamais les pieds.a éviter pour toute personne désirant profité de bonnes vacances.\n",
      "['Vtt', 'sur', 'le', 'Semnoz,', 'pédalo', 'sur', 'le', 'lac,', 'promenade', 'au', 'bord', 'de', \"l'eau\", '(superbe),', \"l'ambiance\", 'de', 'la', 'vielle', 'ville,', 'pti', 'resto', 'super', 'sympa...', 'vraiment', 'vraiment', 'bien....', 'I', 'love', 'Annecy', '....', ':-)', '||', 'ville', 'magnifique', 'avec', 'beaucoup', 'de', 'charme', 'quand', 'je', 'vais', 'a', 'annecy', 'j', 'ai', 'l', 'impresssion', 'de', 'ne', 'plus', 'etre', 'en', 'francepas', 'mal', 'de', 'choses', 'a', 'visiter', 'notamment', 'les', 'gorges', 'du', 'fier', 'non', 'loin', 'du', 'centre', 'balade', 'en', 'bateau', 'sur', 'le', 'lac', 'vieille', 'ville', 'typiqueet', 'de', 'tres', 'bons', 'restaurants', 'mais', 'aussi', 'un', 'joli', 'marche', 'le', 'dimanche', '||', 'Cet', 'endroit', 'est', 'exceptionnel', \"c'est\", \"d'ailleurs\", 'pour', 'cela', 'que', 'plusieurs', 'personnes', 'traversent', 'la', 'France', 'pour', 'venir', 'apprécier', 'ce', 'lac.Surtout', 'agréable', 'en', 'été', 'avec', 'ses', 'différentes', 'animations', 'dansantes', 'ou', 'artistiques.Lieu', 'de', 'convivialité', 'pour', 'aussi', 'bien', 'se', 'balader,', 'se', 'poser', 'sur', 'la', 'pelouse', 'ou', 'bien', 'faire', 'du', 'pédalo', \"l'été\", 'pour', 'pouvoir', 'explorer', 'les', 'différents', 'horizons', 'du', 'lac', 'et', 'ses', 'verdures.', '||', 'Vous', 'pouvez', 'y', 'trouver', 'tout:', 'les', 'montagnes', 'pour', 'les', 'randonnées,', 'le', 'lac', 'avec', 'de', \"l'eau\", 'transparente', 'pour', 'se', 'baigner', 'et', 'les', 'rues', 'anciennes,', 'plein', 'de', 'bâtiments', 'splendides.....', '||', 'Destination', 'idéale', 'pour', 'ceux', 'qui', 'aiment', 'la', 'baignade', '(eau', 'du', 'lac', 'excellente', 'et', 'de', 'tres', 'bonne', 'qualité),', 'et', 'la', 'montagne', '(randonnées', 'de', 'tous', 'niveaux).Cadre', 'magnifique', 'pour', 'passer', 'de', 'tres', 'bonnes', 'vacances', '||', 'Mai', '2010,', 'besoin', 'de', 'vacances', 'et', 'de', 'dépaysement', 'à', 'petit', 'prix', 'urgent.Je', 'propose', 'donc', 'à', 'mon', 'cher', 'et', 'tendre', 'une', 'virée', 'romantique', \"d'une\", 'semaine', 'en', 'Haute-Savoie.', 'Je', 'connaissais', 'la', 'région', 'pour', 'y', 'être', 'aller', 'petite', 'avec', 'mes', 'grand-parents,Nous', 'partons', 'donc', 'sur', 'Internet', 'à', 'la', 'recherche', \"d'un\", 'gîte', 'à', 'proximité', \"d'Annecy.\", 'Après', 'plusieurs', 'jours', 'de', 'recherche', 'nous', 'trouvons', 'une', 'annonce', 'sur', '\"le', 'bon', 'coin\",', '250', '€', 'la', 'semaine', 'pour', 'un', 'P2', 'à', 'Villard-Dessous(commune', 'de', 'Manigod).Arrivé', 'sur', 'place', 'le', 'spectacle', 'nous', 'laisse', 'sans', 'voix,', 'le', 'paysage', 'est', 'fabuleux,', 'les', 'montagnes', 'face', 'à', 'nous', 'enneigées.Nous', 'avons', 'profiter', 'de', 'notre', 'semaine', 'pour', 'visiter', 'Annecy,', 'faire', 'une', 'ballade', 'en', 'bateau', 'sur', 'le', 'Lac', \"d'Annecy,\", 'aller', 'dans', 'une', 'crémerie', 'acheter', 'le', 'nécessaire', 'pour', 'la', 'fondue', 'savoyarde,', 'visiter', 'le', 'Museùm', 'de', 'Genève', '(1', 'heure', 'de', 'route),', 'voir', 'le', 'Lac', 'Léman,', 'visiter', 'Yvoire', 'qui', 'est', 'un', 'magnifique', 'petit', 'village', 'médiéval', 'et', 'piéton', '!', '.', 'Nous', 'avons', 'été', 'voir', 'la', 'cascade', 'du', 'Rouget,', 'dite', 'la', 'Reine', 'des', 'Alpes', 'ou', 'nous', 'avons', 'été', 'arrosé', \"d'embruns,\", 'visiter', 'La', 'gorge', 'du', 'pont', 'du', 'diable.', 'et', 'encore', 'beaucoup', 'de', 'promenade', 'et', 'marché', 'dans', 'les', 'villages', 'au', 'abord', \"d'annecy.\", \"C'est\", 'une', 'très', 'belle', 'région', 'que', 'nous', 'conseillons', 'à', 'tous,', 'petit', 'et', 'grand.', 'Il', 'y', 'a', 'de', 'nombreuses', 'activités', 'pour', 'tous', 'les', 'budgets,', 'notre', 'semain', 'nous', 'est', 'revenu', 'à', 'environ', '600', '€,', 'sorties,', 'essence,', 'péage,', 'nourriture,', 'location', 'gîte', 'compris.Une', 'des', 'choses', 'que', 'nous', 'regrettons', ':', 'ne', 'pas', 'avoir', 'vu', 'les', 'marmottes', '!A', 'noter', 'aussi', 'que', 'si', 'vous', 'aimez', 'visiter', 'il', 'faudra', 'rouler.', '||', 'cette', 'ville', \"m'enchante\", 'depuis', 'une', 'dizaine', \"d'annéestant\", 'par', 'son', 'tourisme', 'que', 'par', 'ses', 'habitantscette', 'ville', 'est', 'le', 'reflet', 'parfait', 'de', 'mes', \"vacancesj'ai\", 'besoin', \"d'y\", 'aller', 'au', 'moins', 'une', 'fois', 'par', 'an', 'pour', 'me', 'resourcer', '||', 'magnifique', 'ville,', 'des', 'activités', 'pour', 'tous:', 'proximité', 'des', 'stations', 'de', 'skis,', 'activités', 'nautiques', \"l'été,\", 'une', 'ville', 'culturelle', 'et', 'historique', 'magnifique,', 'et', 'un', 'large', 'choix', 'de', 'shopping!!Note', 'spéciale', 'pour', 'le', 'restaurant', 'le', '\"20/Vins\"', 'dans', 'la', 'vieille', 'ville', '(passage', 'Golliardi)', ',', 'une', 'formule', 'originale', 'pour', 'déguster', 'un', 'large', 'choix', 'de', 'bons', 'vins', 'et', 'des', 'plats', 'diversifiés:', 'du', 'risotto', 'au', 'couscous', 'en', 'passant', 'par', 'la', 'souris', \"d'agneau\", 'ou', 'bien', 'un', 'Mont', \"d'or!!\", 'en', 'prime,', 'une', 'déco', 'moderne', 'cosy', 'et', 'raffinée!', '||', 'Ville', 'très', 'agréable.Pour', 'une', 'promenade', 'sur', 'le', 'lac,', 'il', 'est', 'possible', 'de', 'louer', 'pédalos', 'et', 'autres', 'bateaux', 'avec', 'ou', 'sans', 'moteur,', 'malheureusement', 'une', 'entente', 'sur', 'les', 'prix', 'fausse', 'totalement', 'la', 'concurrence.La', 'ville', 'a', 'décidé', 'de', 'faire', 'les', 'poches', 'des', 'visiteurs', 'grâce', 'au', 'tarif', 'prohibitif', 'des', 'parkings', 'municipaux.La', 'ville', \"s'avère\", 'tout', 'à', 'fait', 'adaptée', 'aux', 'personnes', 'âgées', 'ou', 'couples', 'sans', 'enfant(s).', '||', 'une', 'jolie', 'ville,entourée', 'de', 'belles', 'montagnes', 'avec', 'un', 'lac', 'magnifique.par', 'contre', 'une', 'trés', 'mauvaise', 'mentalité,un', 'trés', 'mauvais', 'accueille,avec', 'un', 'grand', 'nombre', 'de', 'restaurants', '\"piege', 'a', 'touriste\"', ',les', 'prix', 'sont', 'carrement', 'abusifs', 'et', 'les', 'plats', 'plus', 'que', 'médiocres', '.les', 'habitants', 'sont', 'froid,sans', 'intéréts,rustres', 'et', 'vraiment', 'mal', 'polies.ils', \"n'ont\", 'aucun', 'savoir', 'vivre.ils', 'ne', 'sont', 'absolument', 'pas', 'souriant(méme', 'dans', 'les', 'commerces!).je', \"n'y\", 'remettrais', 'plus', 'jamais', 'les', 'pieds.a', 'éviter', 'pour', 'toute', 'personne', 'désirant', 'profité', 'de', 'bonnes', 'vacances.']\n",
      "vtt semnoz pédalo lac promenade bord eau superbe ambiance vielle ville pti resto super sympa vraiment vraiment bien love annecy ville magnifique beaucoup charme quand vais annecy impresssion plus etre francepas mal choses visiter notamment gorge fier non loin centre balade bateau lac vieille ville typiqueet tres bons restaurant aussi joli marche dimanche cet endroit exceptionnel ailleurs cela plusieurs personnes traversent france venir apprécier lac surtout agréable différentes animation dansantes artistiques lieu convivialité aussi bien balader poser pelouse bien faire pédalo pouvoir explorer différents horizon lac verdure pouvez trouver tout montagnes randonnées lac eau transparente baigner rue anciennes plein bâtiments splendides destination idéale ceux aiment baignade eau lac excellente tres bonne qualité montagne randonnées tous niveaux cadre magnifique passer tres bonnes vacances mai 2010 besoin vacances dépaysement petit prix urgent propose donc cher tendre virée romantique semaine haute savoie connaissais région être aller petite grand parent partons donc internet recherche gîte proximité annecy après plusieurs jours recherche trouvons annonce bon coin 250 semaine p2 villard dessous commune manigod arrivé place spectacle laisse sans voix paysage fabuleux montagnes face enneigées profiter semaine visiter annecy faire ballade bateau lac annecy aller crémerie acheter nécessaire fondue savoyarde visiter museùm genève heure route voir lac léman visiter yvoire magnifique petit village médiéval piéton voir cascade rouget dite reine alpes arrosé embruns visiter gorge pont diable encore beaucoup promenade marché village abord annecy très belle région conseillons tous petit grand nombreuses activités tous budget semain revenu environ 600 sortie essence péage nourriture location gîte compris choses regrettons avoir vu marmottes noter aussi si aimez visiter faudra rouler cette ville enchante depuis dizaine annéestant tourisme habitantscette ville reflet parfait vacancesj besoin aller moins fois an resourcer magnifique ville activités tous proximité station ski activités nautiques ville culturelle historique magnifique large choix shopping note spéciale restaurant 20 vins vieille ville passage golliardi formule originale déguster large choix bons vins plat diversifiés risotto couscous passant souris agneau bien mont or prime déco moderne cosy raffinée ville très agréable promenade lac possible louer pédalos autres bateaux sans moteur malheureusement entente prix fausse totalement concurrence ville décidé faire poches visiteurs grâce tarif prohibitif parking municipaux ville avère tout fait adaptée personnes âgées couple sans enfant jolie ville entourée belle montagnes lac magnifique contre trés mauvaise mentalité trés mauvais accueille grand nombre restaurant piege touriste prix carrement abusifs plat plus médiocres habitant froid sans intéréts rustres vraiment mal polies aucun savoir vivre absolument souriant méme commerce remettrais plus jamais pieds éviter toute personne désirant profité bonnes vacances\n",
      "['vtt', 'semnoz', 'pédalo', 'lac', 'promenade', 'bord', 'eau', 'superbe', 'ambiance', 'vielle', 'ville', 'pti', 'resto', 'super', 'sympa', 'vraiment', 'vraiment', 'bien', 'love', 'annecy', 'ville', 'magnifique', 'beaucoup', 'charme', 'quand', 'vais', 'annecy', 'impresssion', 'plus', 'etre', 'francepas', 'mal', 'choses', 'visiter', 'notamment', 'gorge', 'fier', 'non', 'loin', 'centre', 'balade', 'bateau', 'lac', 'vieille', 'ville', 'typiqueet', 'tres', 'bons', 'restaurant', 'aussi', 'joli', 'marche', 'dimanche', 'cet', 'endroit', 'exceptionnel', 'ailleurs', 'cela', 'plusieurs', 'personnes', 'traversent', 'france', 'venir', 'apprécier', 'lac', 'surtout', 'agréable', 'différentes', 'animation', 'dansantes', 'artistiques', 'lieu', 'convivialité', 'aussi', 'bien', 'balader', 'poser', 'pelouse', 'bien', 'faire', 'pédalo', 'pouvoir', 'explorer', 'différents', 'horizon', 'lac', 'verdure', 'pouvez', 'trouver', 'tout', 'montagnes', 'randonnées', 'lac', 'eau', 'transparente', 'baigner', 'rue', 'anciennes', 'plein', 'bâtiments', 'splendides', 'destination', 'idéale', 'ceux', 'aiment', 'baignade', 'eau', 'lac', 'excellente', 'tres', 'bonne', 'qualité', 'montagne', 'randonnées', 'tous', 'niveaux', 'cadre', 'magnifique', 'passer', 'tres', 'bonnes', 'vacances', 'mai', '2010', 'besoin', 'vacances', 'dépaysement', 'petit', 'prix', 'urgent', 'propose', 'donc', 'cher', 'tendre', 'virée', 'romantique', 'semaine', 'haute', 'savoie', 'connaissais', 'région', 'être', 'aller', 'petite', 'grand', 'parent', 'partons', 'donc', 'internet', 'recherche', 'gîte', 'proximité', 'annecy', 'après', 'plusieurs', 'jours', 'recherche', 'trouvons', 'annonce', 'bon', 'coin', '250', 'semaine', 'p2', 'villard', 'dessous', 'commune', 'manigod', 'arrivé', 'place', 'spectacle', 'laisse', 'sans', 'voix', 'paysage', 'fabuleux', 'montagnes', 'face', 'enneigées', 'profiter', 'semaine', 'visiter', 'annecy', 'faire', 'ballade', 'bateau', 'lac', 'annecy', 'aller', 'crémerie', 'acheter', 'nécessaire', 'fondue', 'savoyarde', 'visiter', 'museùm', 'genève', 'heure', 'route', 'voir', 'lac', 'léman', 'visiter', 'yvoire', 'magnifique', 'petit', 'village', 'médiéval', 'piéton', 'voir', 'cascade', 'rouget', 'dite', 'reine', 'alpes', 'arrosé', 'embruns', 'visiter', 'gorge', 'pont', 'diable', 'encore', 'beaucoup', 'promenade', 'marché', 'village', 'abord', 'annecy', 'très', 'belle', 'région', 'conseillons', 'tous', 'petit', 'grand', 'nombreuses', 'activités', 'tous', 'budget', 'semain', 'revenu', 'environ', '600', 'sortie', 'essence', 'péage', 'nourriture', 'location', 'gîte', 'compris', 'choses', 'regrettons', 'avoir', 'vu', 'marmottes', 'noter', 'aussi', 'si', 'aimez', 'visiter', 'faudra', 'rouler', 'cette', 'ville', 'enchante', 'depuis', 'dizaine', 'annéestant', 'tourisme', 'habitantscette', 'ville', 'reflet', 'parfait', 'vacancesj', 'besoin', 'aller', 'moins', 'fois', 'an', 'resourcer', 'magnifique', 'ville', 'activités', 'tous', 'proximité', 'station', 'ski', 'activités', 'nautiques', 'ville', 'culturelle', 'historique', 'magnifique', 'large', 'choix', 'shopping', 'note', 'spéciale', 'restaurant', '20', 'vins', 'vieille', 'ville', 'passage', 'golliardi', 'formule', 'originale', 'déguster', 'large', 'choix', 'bons', 'vins', 'plat', 'diversifiés', 'risotto', 'couscous', 'passant', 'souris', 'agneau', 'bien', 'mont', 'or', 'prime', 'déco', 'moderne', 'cosy', 'raffinée', 'ville', 'très', 'agréable', 'promenade', 'lac', 'possible', 'louer', 'pédalos', 'autres', 'bateaux', 'sans', 'moteur', 'malheureusement', 'entente', 'prix', 'fausse', 'totalement', 'concurrence', 'ville', 'décidé', 'faire', 'poches', 'visiteurs', 'grâce', 'tarif', 'prohibitif', 'parking', 'municipaux', 'ville', 'avère', 'tout', 'fait', 'adaptée', 'personnes', 'âgées', 'couple', 'sans', 'enfant', 'jolie', 'ville', 'entourée', 'belle', 'montagnes', 'lac', 'magnifique', 'contre', 'trés', 'mauvaise', 'mentalité', 'trés', 'mauvais', 'accueille', 'grand', 'nombre', 'restaurant', 'piege', 'touriste', 'prix', 'carrement', 'abusifs', 'plat', 'plus', 'médiocres', 'habitant', 'froid', 'sans', 'intéréts', 'rustres', 'vraiment', 'mal', 'polies', 'aucun', 'savoir', 'vivre', 'absolument', 'souriant', 'méme', 'commerce', 'remettrais', 'plus', 'jamais', 'pieds', 'éviter', 'toute', 'personne', 'désirant', 'profité', 'bonnes', 'vacances']\n"
     ]
    }
   ],
   "source": [
    "corpus = agg_df['reviews'].tolist()\n",
    "print(corpus[0])\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "print(tokenized_corpus[0])\n",
    "processed_corpus = [clean_text(doc) for doc in corpus]\n",
    "print(processed_corpus[0])\n",
    "processed_tokenized_corpus = [doc.split(' ') for doc in processed_corpus]\n",
    "print(processed_tokenized_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 1, 17, 15, 14, 4, 23, 3, 21, 29, 33, 2, 18, 13, 34, 0, 24, 6, 35, 16, 20, 8, 28, 11, 10, 31, 26, 22, 25, 30, 19, 32, 27, 5, 12, 9]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n_queries = 36\n",
    "random.seed(42)\n",
    "query_ids = random.sample(range(len(corpus)), n_queries)\n",
    "print(query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 without NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20000000000000018, 0.5999999999999996, 0.7000000000000002, 0.6000000000000001, 1.3666666666666671, 0.7000000000000002, 0.666666666666667, 0.9333333333333331, 0.5, 0.666666666666667, 0.20000000000000018, 0.24285714285714333, 0.6000000000000001, 0.20000000000000018, 0.4666666666666668, 0.2999999999999998, 0.7000000000000002, 0.8666666666666667, 0.22857142857142865, 0.3666666666666667, 0.8000000000000003, 0.033333333333333215, 0.5, 0.40000000000000036, 1.3666666666666671, 0.5, 0.8000000000000003, 0.6666666666666665, 0.7000000000000002, 2.0333333333333337, 0.5, 0.20000000000000018, 0.023809523809523725, 0.0, 0.16666666666666696, 0.4333333333333331]\n",
      "0.5619047619047621\n",
      "[20, 0, 20, 17, 20, 20, 17, 15, 17, 17, 17, 26, 26, 20, 28, 20, 20, 20, 28, 28, 26, 20, 20, 17, 20, 17, 20, 13, 20, 20, 3, 20, 2, 20, 3, 26]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "for query_id in query_ids:\n",
    "    query = corpus[query_id]\n",
    "    tokenized_query = query.split(\" \")\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    doc_id = doc_scores.argsort()[-2]\n",
    "    best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    errors.append(abs_error)\n",
    "    \n",
    "# Calculate the mean ERROR\n",
    "mean_error_bm25_baseline = np.mean(errors)\n",
    "print(errors)\n",
    "print(mean_error_bm25_baseline)\n",
    "print(best_doc_ids)\n",
    "model_results['bm25_baseline'] = mean_error_bm25_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 with NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20000000000000018, 0.5, 0.10000000000000009, 0.6000000000000001, 0.8666666666666671, 0.40000000000000036, 0.16666666666666696, 0.9333333333333331, 0.5, 0.666666666666667, 0.20000000000000018, 0.35714285714285676, 0.20000000000000018, 0.20000000000000018, 0.4666666666666668, 0.2999999999999998, 0.14285714285714324, 0.30952380952380976, 0.22857142857142865, 0.3666666666666667, 0.8000000000000003, 0.033333333333333215, 0.20000000000000018, 0.09999999999999964, 0.666666666666667, 0.16666666666666696, 0.10000000000000009, 0.8666666666666667, 0.5, 1.5333333333333337, 0.9333333333333331, 0.5, 0.033333333333333215, 0.0, 0.2999999999999998, 0.33333333333333304]\n",
      "0.41031746031746036\n",
      "[20, 18, 26, 17, 28, 0, 13, 15, 17, 17, 17, 13, 5, 20, 28, 20, 2, 2, 28, 28, 26, 5, 0, 13, 24, 9, 17, 20, 13, 28, 26, 24, 28, 20, 28, 24]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "processed_bm25 = BM25Okapi(processed_tokenized_corpus)\n",
    "\n",
    "processed_errors = []\n",
    "processed_best_doc_ids = []\n",
    "\n",
    "for query_id in query_ids:\n",
    "    query = processed_corpus[query_id]\n",
    "    tokenized_query = query.split(\" \")\n",
    "    doc_scores = processed_bm25.get_scores(tokenized_query)\n",
    "    doc_id = doc_scores.argsort()[-2]\n",
    "    processed_best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    processed_errors.append(abs_error)\n",
    "    \n",
    "# Calculate the mean ERROR\n",
    "mean_error_bm25_preprocessed = np.mean(processed_errors)\n",
    "print(processed_errors)\n",
    "print(mean_error_bm25_preprocessed)\n",
    "print(processed_best_doc_ids)\n",
    "model_results['bm25_preprocessed'] = mean_error_bm25_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF without NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20000000000000018, 0.5999999999999996, 0.7000000000000002, 0.6000000000000001, 1.3666666666666671, 0.7000000000000002, 0.033333333333333215, 0.33333333333333304, 1.1, 0.666666666666667, 0.20000000000000018, 0.14285714285714324, 0.20000000000000018, 0.20000000000000018, 0.4666666666666668, 0.2999999999999998, 0.7000000000000002, 0.8666666666666667, 0.27142857142857135, 0.8666666666666667, 0.7000000000000002, 0.033333333333333215, 0.5, 0.2999999999999998, 1.3666666666666671, 0.20000000000000018, 0.8000000000000003, 0.6666666666666665, 0.7000000000000002, 2.0333333333333337, 0.9333333333333331, 0.20000000000000018, 0.033333333333333215, 0.0, 0.20000000000000018, 0.33333333333333304]\n",
      "0.542063492063492\n",
      "[20, 0, 20, 17, 20, 20, 20, 17, 15, 17, 17, 17, 20, 20, 28, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 13, 20, 20, 26, 20, 28, 20, 20, 17]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build TF-IDF matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "\n",
    "errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "for query_id in query_ids:\n",
    "    query = corpus[query_id]\n",
    "    query_vector = tfidf.transform([query])\n",
    "    doc_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    errors.append(abs_error)\n",
    "\n",
    "mean_error_tf_baseline = np.mean(errors)\n",
    "print(errors)\n",
    "print(mean_error_tf_baseline)\n",
    "print(best_doc_ids)\n",
    "model_results['tfidf_baseline'] = mean_error_tf_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF with NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20000000000000018, 0.5999999999999996, 0.10000000000000009, 0.6000000000000001, 0.8666666666666671, 0.40000000000000036, 0.666666666666667, 0.9333333333333331, 0.5, 0.666666666666667, 0.20000000000000018, 0.35714285714285676, 0.09999999999999964, 0.20000000000000018, 0.033333333333333215, 0.2999999999999998, 0.14285714285714324, 0.16666666666666652, 0.22857142857142865, 0.3666666666666667, 0.7000000000000002, 0.666666666666667, 0.5, 0.40000000000000036, 0.666666666666667, 0.16666666666666696, 0.10000000000000009, 0.8666666666666667, 0.7000000000000002, 1.3333333333333335, 0.9333333333333331, 0.09999999999999964, 0.33333333333333304, 0.7000000000000002, 0.0, 0.4333333333333331]\n",
      "0.45079365079365086\n",
      "[20, 0, 26, 17, 28, 0, 17, 15, 17, 17, 17, 13, 0, 20, 5, 20, 2, 17, 28, 28, 17, 17, 5, 17, 17, 9, 17, 20, 20, 17, 26, 0, 12, 17, 13, 26]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build TF-IDF matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(processed_corpus)\n",
    "\n",
    "preprocessed_errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "for query_id in query_ids:\n",
    "    query = processed_corpus[query_id]\n",
    "    query_vector = tfidf.transform([query])\n",
    "    doc_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    preprocessed_errors.append(abs_error)\n",
    "\n",
    "mean_error_tf_preprocessed = np.mean(preprocessed_errors)\n",
    "print(preprocessed_errors)\n",
    "print(mean_error_tf_preprocessed)\n",
    "print(best_doc_ids)\n",
    "model_results['tfidf_preprocessed'] = mean_error_tf_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan T5 without NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ringi_3xz04z7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import sentencepiece\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding documents into embeddings...\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import sentencepiece\n",
    "import torch\n",
    "\n",
    "# Load T5 model and tokenizer\n",
    "model_name = \"t5-base\"  # Change to \"t5-base\" or \"t5-large\" for better results\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5Model.from_pretrained(model_name)\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to encode text into embeddings using T5\n",
    "def encode_text(text, max_length=512):\n",
    "    # Tokenize and prepare inputs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "    # Pass inputs through T5 encoder to get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model.encoder(**inputs)\n",
    "    # Mean pooling of the token embeddings\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Preprocess corpus to get embeddings\n",
    "print(\"Encoding documents into embeddings...\")\n",
    "document_embeddings = np.array([encode_text(doc) for doc in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing queries...\n",
      "[0.09999999999999964, 0.5, 0.666666666666667, 0.8000000000000003, 0.8095238095238102, 0.5, 0.666666666666667, 1.0, 0.16666666666666696, 1.333333333333334, 0.8000000000000003, 0.8095238095238102, 0.5, 0.35714285714285676, 0.16666666666666696, 0.2666666666666666, 0.666666666666667, 0.3666666666666667, 0.07142857142857117, 0.0, 1.3666666666666671, 0.4666666666666668, 0.05714285714285694, 0.06666666666666732, 1.0, 0.6666666666666665, 0.10000000000000009, 0.0, 0.666666666666667, 1.8333333333333335, 0.833333333333333, 1.166666666666667, 0.33333333333333304, 0.033333333333333215, 0.6666666666666665, 0.13333333333333286]\n",
      "Mean ERROR: 0.5538359788359789\n",
      "Best doc IDs: [0, 18, 8, 33, 2, 18, 25, 10, 8, 23, 15, 14, 4, 2, 12, 8, 14, 28, 7, 22, 14, 28, 2, 9, 3, 22, 17, 16, 23, 12, 4, 14, 18, 8, 16, 28]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "print(\"Processing queries...\")\n",
    "for query_id in query_ids:\n",
    "    query = corpus[query_id]\n",
    "    query_embedding = encode_text(query)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    doc_scores = cosine_similarity([query_embedding], document_embeddings).flatten()\n",
    "    \n",
    "    # Get the second-highest score\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    \n",
    "    # Calculate MSE for evaluation\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    errors.append(abs_error)\n",
    "\n",
    "# Calculate the mean ERROR\n",
    "mean_errors_t5s_baseline = np.mean(errors)\n",
    "print(errors)\n",
    "print(f\"Mean ERROR: {mean_errors_t5s_baseline}\")\n",
    "print(\"Best doc IDs:\", best_doc_ids)\n",
    "model_results['t5s_baseline'] = mean_errors_t5s_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan TF with NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding documents into embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Load T5 model and tokenizer\n",
    "model_name = \"t5-base\"  # Change to \"t5-base\" or \"t5-large\" for better results\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5Model.from_pretrained(model_name)\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to encode text into embeddings using T5\n",
    "def encode_text(text, max_length=512):\n",
    "    # Tokenize and prepare inputs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "    # Pass inputs through T5 encoder to get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model.encoder(**inputs)\n",
    "    # Mean pooling of the token embeddings\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Preprocess corpus to get embeddings\n",
    "print(\"Encoding documents into embeddings...\")\n",
    "document_embeddings = np.array([encode_text(doc) for doc in processed_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing queries...\n",
      "[0.20000000000000018, 0.5999999999999996, 0.10000000000000009, 0.6000000000000001, 0.8666666666666671, 0.40000000000000036, 0.666666666666667, 0.9333333333333331, 0.5, 0.666666666666667, 0.20000000000000018, 0.35714285714285676, 0.09999999999999964, 0.20000000000000018, 0.033333333333333215, 0.2999999999999998, 0.14285714285714324, 0.16666666666666652, 0.22857142857142865, 0.3666666666666667, 0.7000000000000002, 0.666666666666667, 0.5, 0.40000000000000036, 0.666666666666667, 0.16666666666666696, 0.10000000000000009, 0.8666666666666667, 0.7000000000000002, 1.3333333333333335, 0.9333333333333331, 0.09999999999999964, 0.33333333333333304, 0.7000000000000002, 0.0, 0.4333333333333331]\n",
      "Mean ERROR: 0.45079365079365086\n",
      "Best doc IDs: [28, 19, 33, 28, 23, 27, 14, 10, 11, 14, 26, 13, 34, 2, 16, 28, 13, 35, 6, 34, 7, 11, 0, 21, 3, 22, 33, 16, 29, 12, 1, 14, 34, 7, 34, 16]\n"
     ]
    }
   ],
   "source": [
    "processed_errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "print(\"Processing queries...\")\n",
    "for query_id in query_ids:\n",
    "    query = processed_corpus[query_id]\n",
    "    query_embedding = encode_text(query)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    doc_scores = cosine_similarity([query_embedding], document_embeddings).flatten()\n",
    "    \n",
    "    # Get the second-highest score\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    \n",
    "    # Calculate MSE for evaluation\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    processed_errors.append(abs_error)\n",
    "\n",
    "# Calculate the mean ERROR\n",
    "mean_error_t5s_preprocessed = np.mean(processed_errors)\n",
    "print(preprocessed_errors)\n",
    "print(f\"Mean ERROR: {mean_error_tf_preprocessed}\")\n",
    "print(\"Best doc IDs:\", best_doc_ids)\n",
    "model_results['t5s_preprocessed'] = mean_error_t5s_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09999999999999964, 0.16666666666666696, 0.0, 0.6000000000000001, 0.8666666666666671, 0.5, 1.333333333333334, 0.16666666666666696, 0.16666666666666696, 0.8666666666666671, 0.3666666666666667, 1.4761904761904767, 0.16666666666666696, 0.5, 0.5, 0.2666666666666666, 0.5, 0.3666666666666667, 0.02857142857142847, 0.3666666666666667, 0.033333333333333215, 0.033333333333333215, 0.8666666666666671, 0.5666666666666669, 0.666666666666667, 0.0, 0.6000000000000001, 0.6666666666666665, 0.5, 2.0000000000000004, 0.33333333333333304, 0.16666666666666696, 0.33333333333333304, 0.20000000000000018, 0.6666666666666665, 0.33333333333333304]\n",
      "0.4797619047619049\n",
      "[11, 19, 24, 24, 28, 18, 29, 18, 8, 28, 22, 30, 3, 25, 27, 34, 12, 28, 0, 28, 8, 20, 29, 22, 25, 13, 18, 12, 13, 34, 12, 3, 12, 12, 22, 25]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Encode documents into embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight BERT-based model\n",
    "embeddings = model.encode(corpus)\n",
    "\n",
    "errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "for query_id in query_ids:\n",
    "    query = corpus[query_id]\n",
    "    query_embedding = model.encode([query])\n",
    "    doc_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    errors.append(abs_error)\n",
    "\n",
    "mean_error_bert_baseline = np.mean(errors)\n",
    "print(errors)\n",
    "print(mean_error_bert_baseline)\n",
    "print(best_doc_ids)\n",
    "model_results['bert_baseline'] = mean_error_bert_baseline\n",
    "bert_model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666666666666696, 0.5999999999999996, 1.3333333333333335, 0.8000000000000003, 0.8666666666666671, 0.5, 0.5, 0.09523809523809579, 0.5, 0.8095238095238102, 0.3666666666666667, 0.05714285714285694, 0.09999999999999964, 0.09999999999999964, 2.0000000000000004, 0.02857142857142847, 0.40000000000000036, 0.3666666666666667, 0.02857142857142847, 0.3666666666666667, 0.033333333333333215, 0.3333333333333339, 0.05714285714285694, 0.5666666666666669, 1.0, 0.07142857142857117, 0.5000000000000004, 0.3666666666666667, 0.666666666666667, 1.8333333333333335, 0.9999999999999996, 0.2999999999999998, 1.5000000000000004, 0.033333333333333215, 1.8333333333333335, 0.06666666666666732]\n",
      "0.5596560846560846\n",
      "[9, 11, 30, 33, 28, 18, 27, 35, 17, 2, 22, 28, 0, 0, 30, 35, 0, 28, 0, 28, 8, 3, 2, 22, 3, 35, 0, 33, 23, 12, 22, 28, 30, 34, 30, 0]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Encode documents into embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight BERT-based model\n",
    "embeddings = model.encode(processed_corpus)\n",
    "\n",
    "processed_errors = []\n",
    "best_doc_ids = []\n",
    "\n",
    "# Iterate through random queries\n",
    "for query_id in query_ids:\n",
    "    query = processed_corpus[query_id]\n",
    "    query_embedding = model.encode([query])\n",
    "    doc_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    doc_id = np.argsort(doc_scores)[-2]  # Second-highest score\n",
    "    best_doc_ids.append(doc_id)\n",
    "    abs_error = abs(agg_df.iloc[query_id]['average_rating'] - agg_df.iloc[doc_id]['average_rating'])\n",
    "    processed_errors.append(abs_error)\n",
    "\n",
    "mean_error_bert_preprocessed = np.mean(processed_errors)\n",
    "print(processed_errors)\n",
    "print(mean_error_bert_preprocessed)\n",
    "print(best_doc_ids)\n",
    "model_results['bert_preprocessed'] = mean_error_bert_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(model_results, orient='index', columns=['ERROR'])\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Model'})\n",
    "results_df = results_df.sort_values('ERROR')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='ERROR', y='Model', data=results_df, palette='viridis', hue='Model')\n",
    "plt.title('Average Error of Different Models')\n",
    "plt.xlabel('Average Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation based on review and emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Matches:\n",
      "Destination: Bruxelles N Aero\n",
      "Document: ['amour', 'porte', 'ville', 'dépend', 'évidemment', 'cherche', 'lu', 'commentaires', 'négatifs', 'rome', 'paris', 'trouve', 'personnellement', 'admirables', 'bruxelles', 'taille', 'grande', 'ville', 'province', 'peine', 'deux', 'million', 'habitant', 'grande', 'banlieue', 'peut', 'donc', 'comparer', 'paris', 'londres', 'rome', 'proportionnellement', 'taille', 'ville', 'riche', 'musées', 'oeuvre', 'art', 'tout', 'fait', 'remarquables', 'crois', 'déplorable', 'service', 'touristique', 'cette', 'ville', 'mette', 'trop', 'accent', 'exception', 'grand', 'place', 'plus', 'médiocre', 'manneken', 'pi', 'atomium', 'assez', 'médiocres', 'restaurant', 'rue', 'bouchers', 'plus', 'populaire', 'habite', 'cette', 'ville', 'depuis', 'nombre', 'années', 'trouve', 'agréable', 'vivre', 'bons', 'cinémas', 'bons', 'théâtres', 'excellentes', 'salles', 'concert', 'surtout', 'appartements', 'très', 'confortables', 'prix', 'relativement', 'abordables', 'espace', 'relativement', 'peu', 'habitant', 'très', 'beau', 'hôtels', 'maître', 'atmosphère', 'très', 'détendue', 'gros', 'défauts', 'cette', 'ville', 'relative', 'saleté', 'manque', 'attention', 'jardins', 'manques', 'amour', 'beaucoup', 'habitant', 'semble', 'édiles', 'locaux', 'veuillent', 'derniers', 'temp', 'faire', 'effort', 'bref', 'ville', 'mérite', 'vraiment', 'beaucoup', 'mieux', 'titre', 'capitale', 'chocolat', 'pris', 'car', 'panoramique', 'faisant', 'tour', 'ville', 'très', 'agréable', 'car', 'voyons', 'choses', 'primordiales', 'pourrions', 'faire', '2hpar', 'contre', 'bcq', 'embouteillages', 'après', 'avoir', 'repris', 'véhicule', 'garé', 'parking', 'tourné', 'afin', 'sortir', 'ville', 'car', 'aucun', 'panneau', 'signalisation', 'indiquant', 'villes', 'alentour', 'simplement', 'autoroute', 'indiquant', 'ring', 'quelle', 'direction', 'devant', 'rendre', 'genval', 'malheureusement', 'connaissions', 'autoroute', 'e411', 'après', 'maints', 'arrêts', 'demander', 'route', 'enfin', 'trouvé', 'bonne', 'personne', 'bien', '1ère', 'fois', 'cela', 'arrive', 'reviendrons', 'si', 'tot', 'cette', 'ville', 'laissé', 'amer', 'souvenir', 'francais', 'parisiens', 'pourtant', 'habitués', 'circulation', 'autoroutes', 'périphériques', 'ville', 'magnifique', 'lorsqu', 'fait', 'beau', 'préférez', 'période', 'avril', 'septembre', 'visiter', 'cette', 'ville', 'bien', 'pendant', 'période', 'fêtes', 'plaisirs', 'hiver', 'parcs', 'très', 'nombreux', 'avenue', 'boisées', 'tramway', 'moyen', 'bon', 'marché', 'découvrir', 'ville', 'plus', 'beau', 'endroits', 'centre', 'ville', 'brux', 'ville', 'uccle', 'ixelles', 'heyzel', 'quartier', 'européen', 'tres', 'belle', 'ville', 'tout', 'petit', 'peu', 'decu', 'capitale', 'comparé', 'rome', 'paris', 'car', 'ça', 'fait', 'peu', 'ville', 'province', 'enormement', 'chose', 'voir', 'faire', 'moins', '1x', 'ça', 'vaut', 'coup', 'très', 'bien', 'logés', 'ajouté', 'agrément', 'séjour', 'bruxelles', 'ville', 'très', 'agréable', 'surprise', 'taille', 'échelle', 'humaine', 'ville', 'connue', 'monde', 'entier', 'mélange', 'population', 'personne', 'parlant', 'langues', 'différentes', 'touristes', 'attraction', 'onu', 'sans', 'doute', 'très', 'bien', 'accueillis', 'partout', 'où', 'allés', 'ville', 'dégage', 'atmosphère', 'plaisante', 'stress', 'apparemment', 'beaucoup', 'chose', 'voir', 'plan', 'architectural', 'culturel', 'ville', 'passionnante', 'découvrir', 'riche', 'musées', 'bâtiments', 'vie', 'tout', 'court', 'habitant', 'galeries', 'très', 'branchées', 'côté', 'épicerie', 'orientale', 'cafés', 'merveilleux', 'mélange', 'architecture', 'magnifique', 'bâtisses', 'affreuses', 'vraiment', 'belle', 'ville', 'si', 'vivante', 'jours', 'bruxelles', 'découverte', 'ville', 'pleine', 'charme', 'grand', 'place', 'merveille', 'architecture', 'rue', 'ruelles', 'bordant', 'grand', 'place', 'moment', 'détente', 'bonne', 'humeur', 'communicatives', 'répendent', 'table', 'table', 'soleil', 'rdv', 'galeries', 'couvertes', 'dont', 'parle', 'jamais', 'plus', 'superbes', 'galerie', 'reine', 'prince', 'galerie', 'saint', 'hubert', 'manquer', 'makenpis', 'peu', 'décevant', 'belges', 'gagnent', 'être', 'connus', 'manquez', 'musée', 'magritte', 'bruxelles', 'ville', 'propre', 'moderne', 'su', 'garder', 'toutes', 'tradition', 'ambiance', 'garantie', 'vieille', 'ville', 'royale', 'vu', 'arno', 'cette', 'fois', 'ci', 'acheté', 'plein', 'bd', 'bruxelles', 'vraie', 'frontière', 'entre', 'nord', 'sud', 'salut', 'amis', 'cet', 'hôtel', 'proche', 'institution', 'européennes', 'accueil', 'service', 'irréprochables', 'week', 'end', 'nuit', 'revenue', 'petits', 'déjeuners', 'copieux', 'parking', 'privé', '185', 'euro', 'peu', 'loin', 'grand', 'place', 'station', 'métro', 'schumann', '10', 'minute', 'confirme', 'car', 'vi', 'sale', 'ennuyeux', 'gris', 'bien', 'loin', 'image', 'faite', 'faut', 'dire', 'plupart', 'expatriés', 'vivent', 'bulle', 'ixelles', 'uccle', 'pire', 'saleté', 'samedi', 'quartiers', 'comme', 'louise', 'rue', 'neuve', 'ramassage', 'poubelles', 'lieu', 'fois', 'semaine', 'mardi', 'vendredi', 'sac', 'plastique', 'ancienne', 'français', 'donc', 'samedi', 'restent', 'tout', 'éboueurs', 'voulu', 'prendre', 'magnifique', 'dire', 'toison', 'or', 'louise', 'jumeler', 'montaigne', 'là', 'comprends', 'plus', 'rien', 'voir', 'vécu', 'espagne', 'portugal', 'londres', 'également', 'trouve', 'plus', 'propre', 'bruxelles', 'pay', 'nord', 'comme', 'belgique', 'ferait', 'bien', 'prendre', 'exemple', 'pay', 'sud', 'soi', 'disant', 'moins', 'disciplinés', 'nord', 'europe', 'car', 'trs', 'propre', 'très', 'organisés', 'ordure']\n",
      "Score: 2.156197959940309\n",
      "\n",
      "Destination: Lyon Part Dieu\n",
      "Document: ['très', 'belle', 'vieille', 'ville', 'nombreux', 'site', 'voir', 'visiter', 'faut', 'pouvoir', 'déplacer', 'pédestrement', 'découvrir', 'petits', 'joyaux', 'toujours', 'beaucoup', 'monde', 'surtout', 'moment', 'fêtes', 'lumières', 'peut', 'conseiller', 'visite', 'plusieurs', 'jours', 'ruelles', 'bâtiments', 'vieux', 'lyon', 'très', 'sympa', 'visiter', 'sans', 'restriction', 'omettant', 'arrêter', 'nombreux', 'petits', 'bistrots', 'vieille', 'ville', 'ville', 'magnifique', 'excellence', 'gastronomie', 'culture', 'française', 'sejour', 'remplie', 'émerveillement', 'découvertes', 'autant', 'culturelles', 'dégustations', 'diferentes', 'suggestion', 'degustatives', 'vraiment', 'adoré', 'lyon', 'ville', 'remplie', 'belle', 'surprise', 'petits', 'arrondissements', 'bouchons', 'lyinnais', 'belle', 'boutique', 'animation', 'rue', 'verdure', 'eau', 'passé', 'journées', 'mémorables', 'retournerons', 'dès', 'possible', 'visite', 'guidée', 'organisée', 'office', 'tourisme', 'très', 'intéressante', 'groupe', 'explication', 'toujours', 'très', 'audible', 'tous', 'audio', 'guide', 'moyennant', 'participation', 'très', 'utiles', 'visite', 'vélo', 'taxi', 'cœur', 'historique', 'ville', 'magasins', 'soie', 'vitraux', 'traboules', 'monument', 'bâtiments', 'musée']\n",
      "Score: 0.0\n",
      "\n",
      "Destination: Nice\n",
      "Document: ['beaucoup', 'choix', 'concernant', 'restauration', 'belle', 'vieille', 'ville', 'marché', 'fleurs', 'cours', 'saleya', 'ambiance', 'typique', 'cette', 'ville', 'beau', 'bâtiments', 'trop', 'bruit', 'grande', 'ville', 'tout', 'zone', 'pietonne', 'sympa', 'shopping', 'interessant', 'bouffe', 'aussi', 'bonne', 'sauf', 'promenade', 'anglais', 'bord', 'mer', 'magnifique', 'cette', 'ville', 'horrible', 'vacances', 'familleil', 'grand', 'chose', 'faire', 'part', 'si', 'reste', 'joursfaire', 'resto', 'ca', 'vacances', 'quelques', 'bons', 'point', 'comme', 'accueil', 'chaleureux', 'très', 'bel', 'endroit', 'cependant', 'assiettes', 'tapa', 'chères', 'bonnes', '12', 'tranche', 'pin', 'vin', 'rouge', 'servit', '17', 'degrés', 'donc', 'dis', 'goût', 'bouteille', '40', 'téléphone', 'laisse', 'deux', 'message', 'vocales', 'réserver', 'arrivée', 'dit', 'possible', 'réserver', '19h30', '22h', 'demander', 'quitter', 'table', 'car', 'autres', 'client', 'réserves', 'bouteille', 'vodka', '150', 'outrée', 'dit', 'normal', 'laissés', 'message', 'monsieur', 'dit', 'numéro', 'faut', 'savoir', 'deux', 'numéros', 'site', 'officiel', 'décidé', 'partir', 'sans', 'régler', 'note', 'bon', 'règle', 'bien', 'entendu', 'exactement', 'cher', 'monsieur', 'fait', 'passer', 'propriétaire', 'tutoyer', 'traiter', 'tous', 'noms', 'oiseaux', 'pleine', 'rue', 'geste', 'commerciale', 'certainement', 'regeler', 'cette', 'erreur', 'simple', 'excuse', 'monsieur', 'chauve', 'préféré', 'mettre', 'dehors', 'alors', 'donne', '3eme', 'bouteilles', 'certainement', 'fini', 'consommer', 'conclusion', 'service', 'déplorable', 'nourriture', 'bonne', 'tarifs', 'excessifs', 'rapport', 'qualité', 'proposée', 'nice', 'belle', 'ville', 'difficulté', 'trouver', 'parking', 'libres', 'énormément', 'choses', 'voir', 'premier', 'lieu', 'promenade', 'anglais', 'littoral', 'contre', 'trop', 'feu', 'rouge', 'mauvaise', 'circulation', 'route', 'mauvais', 'état', 'notamment', 'gare', 'nice', 'nord', 'rue', 'cessole', 'scandaleux', 'très', 'bon', 'séjour', 'très', 'beau', 'temp', 'prsonnel', 'lhotel', 'accueil', 'très', 'bien', 'gentillesse', 'sourire', 'etc', 'leschambres', 'propres', 'bien', 'tenues', 'restaurant', 'personnel', 'également', 'agréable', 'faisant', 'tout', 'faire', 'plaisirf', 'reviendrons', 'cet', 'hôtel', 'mari', 'malade', 'demandé', 'médecin', 'dna', 'quart', 'heure', 'monsieur', 'occupe', 'cela', 'trouvé', 'visite', 'très', 'loin', 'hôtel', 'trouve', 'cela', 'important', 'génial', 'merci', 'encore', 'passer', 'week', 'end', 'formidable', 'amoureux', 'seul', 'petit', 'regret', 'dejeuner', 'chambre', 'trop', 'cher', 'contenue', 'accueillis', 'gentillement', 'hôtel', 'splendid', 'nice', 'malgré', 'étoiles', 'chambre', 'grande', 'belle', 'belle', 'salle', 'bain', 'point', 'important', 'parking', 'sou', 'hôtel', 'payant', 'indispensable', 'utiliser', 'car', 'garer', 'nice', 'galère', 'proche', 'tramway', 'pu', 'aller', 'spectacle', 'acropolis', '500', 'place', 'massenat', 'pu', 'promener', 'très', 'beau', 'marché', 'noël', 'tout', 'ça', 'sans', 'utiliser', 'voiture', 'rendre', 'séjour', 'encore', 'plus', 'agréable', 'petit', 'déjéuner', 'restaurant', 'situé', 'dernier', 'étage', 'hôtel', 'vue', 'ville', 'nice', 'spa', 'hôtel', 'permet', 'aussi', 'moment', 'détente', 'jaccuzi', 'massage', 'suédois', 'conseillons', 'fortement', 'cet', 'hôtel', 'ville', 'bien', 'connue', 'qualité', 'vie', 'également', 'spécialités', 'culinaire', 'ville', 'où', 'fait', 'bon', 'vivre', 'voyez', 'nombreux', 'article', 'quotidien', 'local', 'insécurité', 'touristes', 'suivis', 'agressés', 'obligés', 'réfugiez', 'restaurant', 'échapper', 'malfrats', 'demandez', 'commerçants', 'vieux', 'nice', 'si', 'lieu', 'sécurisé', 'nuit', 'touristes', 'doit', 'prévenir', 'non', 'faire', 'com']\n",
      "Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Assuming processed_bm25 and processed_corpus are already loaded\n",
    "# processed_bm25 = BM25Okapi(processed_tokenized_corpus)\n",
    "# processed_corpus = [your list of documents]\n",
    "# destinations = [list of destinations corresponding to processed_corpus]\n",
    "\n",
    "# Function to preprocess the user input (tokenization)\n",
    "def preprocess_input(user_input):\n",
    "    return user_input.split(\" \")\n",
    "\n",
    "# Function to predict the top 3 documents based on BM25\n",
    "def predict_top_3(user_input, bm25_model, corpus, destinations):\n",
    "    # Preprocess the user input (tokenization)\n",
    "    tokenized_query = preprocess_input(user_input)\n",
    "    \n",
    "    # Get the document scores for the query\n",
    "    doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "    \n",
    "    # Get the indices of the top 3 documents (highest scores)\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]  # Sort and get the top 3 (in descending order)\n",
    "    \n",
    "    # Retrieve the destinations and documents corresponding to the top 3 matches\n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# Prompt the user for input (a query)\n",
    "user_input = input(\"Please enter your travel review query: \")\n",
    "\n",
    "# Get the prediction (top 3 matches and their destinations)\n",
    "top_3_results = predict_top_3(user_input, processed_bm25, processed_tokenized_corpus, agg_df.destination)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nTop 3 Matches:\")\n",
    "for result in top_3_results:\n",
    "    destination, document, score = result\n",
    "    print(f\"Destination: {destination}\\nDocument: {document}\\nScore: {score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble prediction\n",
    "### BM25 preprocessed + TF-IDF preprocessed + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Ensemble Predictions:\n",
      "Destination: Annecy\n",
      "Score: 0.42992353439331055\n",
      "\n",
      "Destination: Milano P Garibaldi\n",
      "Score: 0.4010082185268402\n",
      "\n",
      "Destination: Geneve\n",
      "Score: 0.39729994535446167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Assuming processed_bm25, processed_corpus, agg_df, and destinations are already loaded\n",
    "\n",
    "# Define the preprocessing function for user input (same as before)\n",
    "def preprocess_input(user_input):\n",
    "    return user_input.split(\" \")\n",
    "\n",
    "# BM25 model\n",
    "def predict_bm25(user_input, bm25_model, corpus, destinations):\n",
    "    tokenized_query = preprocess_input(user_input)\n",
    "    doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# TF-IDF model\n",
    "def predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations):\n",
    "    query_vector = tfidf.transform([user_input])\n",
    "    doc_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# BERT model\n",
    "def predict_bert(user_input, model, embeddings, corpus, destinations):\n",
    "    query_embedding = model.encode([user_input])\n",
    "    doc_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# Ensemble model\n",
    "def ensemble_predict(user_input, bm25_model, tfidf_matrix, tfidf, model, embeddings, corpus, destinations):\n",
    "    # Get predictions from each model\n",
    "    bm25_results = predict_bm25(user_input, bm25_model, corpus, destinations)\n",
    "    tfidf_results = predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations)\n",
    "    bert_results = predict_bert(user_input, model, embeddings, corpus, destinations)\n",
    "    \n",
    "    # Combine the results from all models\n",
    "    combined_results = {}\n",
    "    for result in bm25_results + tfidf_results + bert_results:\n",
    "        destination, document, score = result\n",
    "        if destination not in combined_results:\n",
    "            combined_results[destination] = []\n",
    "        combined_results[destination].append(score)\n",
    "    \n",
    "    # Calculate the average score for each destination\n",
    "    averaged_results = []\n",
    "    for destination, scores in combined_results.items():\n",
    "        avg_score = np.mean(scores)\n",
    "        averaged_results.append((destination, avg_score))\n",
    "    \n",
    "    # Sort by average score and return top 3\n",
    "    averaged_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_3_ensemble = averaged_results[:3]\n",
    "    \n",
    "    return top_3_ensemble\n",
    "\n",
    "# Load the pre-trained models and other variables\n",
    "# Example: processed_bm25, processed_corpus, tfidf_matrix, tfidf, model (BERT), embeddings, destinations\n",
    "\n",
    "# User input query\n",
    "user_input = input(\"Please enter your travel review query: \")\n",
    "\n",
    "# Get the ensemble prediction\n",
    "top_3_ensemble = ensemble_predict(user_input, processed_bm25, tfidf_matrix, tfidf, bert_model, embeddings, processed_corpus, agg_df.destination)\n",
    "\n",
    "# Display the top 3 results\n",
    "print(\"\\nTop 3 Ensemble Predictions:\")\n",
    "for destination, score in top_3_ensemble:\n",
    "    print(f\"Destination: {destination}\\nScore: {score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional streamlit app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export models\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create the 'app_models' directory if it doesn't exist\n",
    "if not os.path.exists('app_models'):\n",
    "    os.makedirs('app_models')\n",
    "\n",
    "# Export BM25 model\n",
    "with open(\"app_models/processed_bm25.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_bm25, f)\n",
    "\n",
    "# Export TF-IDF vectorizer and matrix\n",
    "with open(\"app_models/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open(\"app_models/tfidf_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_matrix, f)\n",
    "\n",
    "# Export BERT model\n",
    "with open(\"app_models/bert_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bert_model, f)\n",
    "\n",
    "# Export embeddings\n",
    "with open(\"app_models/embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "# Export processed_corpus and agg_df.destination (if required)\n",
    "with open(\"app_models/processed_corpus.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_corpus, f)\n",
    "\n",
    "with open(\"app_models/agg_df_destination.pkl\", \"wb\") as f:\n",
    "    pickle.dump(agg_df.destination, f)\n",
    "\n",
    "with open(\"app_models/agg_df_train_emissions.pkl\", \"wb\") as f:\n",
    "    pickle.dump(agg_df.train_emissions, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app with no balance between f1 and emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Save the app code to a Python file and run Streamlit\n",
    "streamlit_code = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the path to the app_models folder\n",
    "models_path = 'app_models/'\n",
    "\n",
    "# Load BM25 model\n",
    "with open(os.path.join(models_path, \"processed_bm25.pkl\"), \"rb\") as f:\n",
    "    processed_bm25 = pickle.load(f)\n",
    "\n",
    "# Load TF-IDF vectorizer and matrix\n",
    "with open(os.path.join(models_path, \"tfidf_vectorizer.pkl\"), \"rb\") as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(models_path, \"tfidf_matrix.pkl\"), \"rb\") as f:\n",
    "    tfidf_matrix = pickle.load(f)\n",
    "\n",
    "# Load BERT model\n",
    "with open(os.path.join(models_path, \"bert_model.pkl\"), \"rb\") as f:\n",
    "    bert_model = pickle.load(f)\n",
    "\n",
    "# Load embeddings\n",
    "with open(os.path.join(models_path, \"embeddings.pkl\"), \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Load processed_corpus and agg_df.destination (if required)\n",
    "with open(os.path.join(models_path, \"processed_corpus.pkl\"), \"rb\") as f:\n",
    "    processed_corpus = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(models_path, \"agg_df_destination.pkl\"), \"rb\") as f:\n",
    "    agg_df_destination = pickle.load(f)\n",
    "\n",
    "# Load the emissions data (agg_df_train_emissions)\n",
    "with open(os.path.join(models_path, \"agg_df_train_emissions.pkl\"), \"rb\") as f:\n",
    "    agg_df_train_emissions = pickle.load(f)\n",
    "\n",
    "# Define the preprocessing function for user input\n",
    "def preprocess_input(user_input):\n",
    "    return user_input.split(\" \")\n",
    "\n",
    "# BM25 model prediction\n",
    "def predict_bm25(user_input, bm25_model, corpus, destinations):\n",
    "    tokenized_query = preprocess_input(user_input)\n",
    "    doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# TF-IDF model prediction\n",
    "def predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations):\n",
    "    query_vector = tfidf.transform([user_input])\n",
    "    doc_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# BERT model prediction\n",
    "def predict_bert(user_input, model, embeddings, corpus, destinations):\n",
    "    query_embedding = model.encode([user_input])\n",
    "    doc_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "def ensemble_predict_with_emissions(user_input, bm25_model, tfidf_matrix, tfidf, model, embeddings, corpus, destinations, emissions_data):\n",
    "    # Get predictions from each model\n",
    "    bm25_results = predict_bm25(user_input, bm25_model, corpus, destinations)\n",
    "    tfidf_results = predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations)\n",
    "    bert_results = predict_bert(user_input, model, embeddings, corpus, destinations)\n",
    "    \n",
    "    # Combine the results from all models\n",
    "    combined_results = {}\n",
    "    for result in bm25_results + tfidf_results + bert_results:\n",
    "        destination, document, score = result\n",
    "        if destination not in combined_results:\n",
    "            combined_results[destination] = []\n",
    "        combined_results[destination].append(score)\n",
    "    \n",
    "    # Calculate the average score for each destination and add emissions data\n",
    "    averaged_results = []\n",
    "    for destination, scores in combined_results.items():\n",
    "        avg_score = np.mean(scores)\n",
    "        \n",
    "        # Retrieve the emission for the destination from emissions_data (which is a pandas Series)\n",
    "        try:\n",
    "            emissions = emissions_data[agg_df_destination == destination].values[0]  # .values[0] to extract the scalar value\n",
    "        except IndexError:\n",
    "            emissions = 0  # Default to 0 if the destination is not found\n",
    "            \n",
    "        averaged_results.append((destination, avg_score, emissions))\n",
    "    \n",
    "    # Sort by average score and return top 3\n",
    "    averaged_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_3_ensemble = averaged_results[:3]\n",
    "    \n",
    "    return top_3_ensemble\n",
    "\n",
    "# Streamlit app code with emissions\n",
    "def run_streamlit_app_with_emissions():\n",
    "    st.title(\"Travel Review Prediction with Ensemble Models (Including Emissions)\")\n",
    "    \n",
    "    # Input field for user query\n",
    "    user_input = st.text_input(\"Enter your travel review query:\")\n",
    "    \n",
    "    if user_input:\n",
    "        st.write(\"User input received:\", user_input)  # Debugging line\n",
    "\n",
    "        # Get the ensemble prediction with emissions\n",
    "        top_3_ensemble_with_emissions = ensemble_predict_with_emissions(user_input, processed_bm25, tfidf_matrix, tfidf, bert_model, embeddings, processed_corpus, agg_df_destination, agg_df_train_emissions)\n",
    "\n",
    "        if top_3_ensemble_with_emissions:\n",
    "            st.write(\"### Top 3 Predictions:\")\n",
    "            for destination, score, emissions in top_3_ensemble_with_emissions:\n",
    "                st.write(f\"**Destination:** {destination}\")\n",
    "                st.write(f\"**Score:** {score:.2f}\")\n",
    "                st.write(f\"**Emissions (kg CO2):** {emissions:.2f}\")\n",
    "                st.write(\"---\")\n",
    "        else:\n",
    "            st.write(\"No predictions found.\")\n",
    "\n",
    "# Run the Streamlit app with emissions data\n",
    "run_streamlit_app_with_emissions()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save the app code to a file\n",
    "with open(\"streamlit_app.py\", \"w\") as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "# Run the Streamlit app (in notebook environment)\n",
    "!streamlit run streamlit_app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Save the app code to a Python file and run Streamlit\n",
    "streamlit_code = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Assuming processed_bm25, processed_corpus, agg_df, and destinations are already loaded\n",
    "\n",
    "# Define the path to the app_models folder\n",
    "models_path = 'app_models/'\n",
    "\n",
    "# Load BM25 model\n",
    "with open(os.path.join(models_path, \"processed_bm25.pkl\"), \"rb\") as f:\n",
    "    processed_bm25 = pickle.load(f)\n",
    "\n",
    "# Load TF-IDF vectorizer and matrix\n",
    "with open(os.path.join(models_path, \"tfidf_vectorizer.pkl\"), \"rb\") as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(models_path, \"tfidf_matrix.pkl\"), \"rb\") as f:\n",
    "    tfidf_matrix = pickle.load(f)\n",
    "\n",
    "# Load BERT model\n",
    "with open(os.path.join(models_path, \"bert_model.pkl\"), \"rb\") as f:\n",
    "    bert_model = pickle.load(f)\n",
    "\n",
    "# Load embeddings\n",
    "with open(os.path.join(models_path, \"embeddings.pkl\"), \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Load processed_corpus and agg_df.destination (if required)\n",
    "with open(os.path.join(models_path, \"processed_corpus.pkl\"), \"rb\") as f:\n",
    "    processed_corpus = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(models_path, \"agg_df_destination.pkl\"), \"rb\") as f:\n",
    "    agg_df_destination = pickle.load(f)\n",
    "\n",
    "# Load the train emissions data\n",
    "with open(os.path.join(models_path, \"agg_df_train_emissions.pkl\"), \"rb\") as f:\n",
    "    agg_df_train_emissions = pickle.load(f)\n",
    "\n",
    "# Preprocessing function for user input\n",
    "def preprocess_input(user_input):\n",
    "    return user_input.split(\" \")\n",
    "\n",
    "# BM25 model\n",
    "def predict_bm25(user_input, bm25_model, corpus, destinations):\n",
    "    tokenized_query = preprocess_input(user_input)\n",
    "    doc_scores = bm25_model.get_scores(tokenized_query)\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# TF-IDF model\n",
    "def predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations):\n",
    "    query_vector = tfidf.transform([user_input])\n",
    "    doc_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# BERT model\n",
    "def predict_bert(user_input, model, embeddings, corpus, destinations):\n",
    "    query_embedding = model.encode([user_input])\n",
    "    doc_scores = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    top_3_idx = np.argsort(doc_scores)[-3:][::-1]\n",
    "    \n",
    "    top_3_results = []\n",
    "    for idx in top_3_idx:\n",
    "        best_match_document = corpus[idx]\n",
    "        best_match_destination = destinations[idx]\n",
    "        top_3_results.append((best_match_destination, best_match_document, doc_scores[idx]))\n",
    "    \n",
    "    return top_3_results\n",
    "\n",
    "# Ensemble model\n",
    "def ensemble_predict(user_input, bm25_model, tfidf_matrix, tfidf, model, embeddings, corpus, destinations):\n",
    "    # Get predictions from each model\n",
    "    bm25_results = predict_bm25(user_input, bm25_model, corpus, destinations)\n",
    "    tfidf_results = predict_tfidf(user_input, tfidf_matrix, tfidf, corpus, destinations)\n",
    "    bert_results = predict_bert(user_input, model, embeddings, corpus, destinations)\n",
    "    \n",
    "    # Combine the results from all models\n",
    "    combined_results = {}\n",
    "    for result in bm25_results + tfidf_results + bert_results:\n",
    "        destination, document, score = result\n",
    "        if destination not in combined_results:\n",
    "            combined_results[destination] = []\n",
    "        combined_results[destination].append(score)\n",
    "    \n",
    "    # Calculate the average score for each destination\n",
    "    averaged_results = []\n",
    "    for destination, scores in combined_results.items():\n",
    "        avg_score = np.mean(scores)\n",
    "        averaged_results.append((destination, avg_score))\n",
    "    \n",
    "    # Sort by average score and return top 3\n",
    "    averaged_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_3_ensemble = averaged_results[:3]\n",
    "    \n",
    "    return top_3_ensemble\n",
    "\n",
    "# Recommendation with Best F1 and Lowest Emissions Balance\n",
    "def recommend_best_destination_with_balance(top_3_ensemble_with_emissions):\n",
    "    # Directly calculate F1 score - emissions for each recommendation\n",
    "    recommendations = []\n",
    "    for destination, f1_score, emissions in top_3_ensemble_with_emissions:\n",
    "        combined_score = f1_score - emissions  # F1 score - emissions (no scaling/normalization)\n",
    "        recommendations.append((destination, combined_score))\n",
    "\n",
    "    # Get the destination with the highest combined score\n",
    "    best_destination = max(recommendations, key=lambda x: x[1])[0]\n",
    "    return best_destination\n",
    "\n",
    "# Streamlit app code\n",
    "def run_streamlit_app_with_best_recommendation():\n",
    "    st.title(\"Travel Review Prediction with Ensemble Models\")\n",
    "    \n",
    "    # Input field for user query\n",
    "    user_input = st.text_input(\"Enter your travel review query:\")\n",
    "    \n",
    "    if user_input:\n",
    "        st.write(\"User input received:\", user_input)  # Debugging line\n",
    "\n",
    "        # Get the ensemble prediction with emissions\n",
    "        top_3_ensemble_with_emissions = ensemble_predict(user_input, processed_bm25, tfidf_matrix, tfidf, bert_model, embeddings, processed_corpus, agg_df_destination)\n",
    "\n",
    "        # Add emissions to the results\n",
    "        top_3_ensemble_with_emissions_and_emissions = []\n",
    "        for (destination, score) in top_3_ensemble_with_emissions:\n",
    "            # Instead of using .index(), use .loc to fetch the emission value\n",
    "            emissions = agg_df_train_emissions.loc[agg_df_destination == destination].values[0]\n",
    "            top_3_ensemble_with_emissions_and_emissions.append((destination, score, emissions))\n",
    "\n",
    "        # Display top 3 predictions with F1 score and emissions\n",
    "        st.write(\"### Top 3 Predictions:\")\n",
    "        for destination, score, emissions in top_3_ensemble_with_emissions_and_emissions:\n",
    "            st.write(f\"**Destination:** {destination}\")\n",
    "            st.write(f\"**F1 Score:** {score:.2f}\")\n",
    "            st.write(f\"**Emissions:** {emissions:.2f} kg CO2\")\n",
    "            st.write(\"---\")\n",
    "        \n",
    "        # Get the best destination based on F1 score and emissions balance\n",
    "        best_destination = recommend_best_destination_with_balance(top_3_ensemble_with_emissions_and_emissions)\n",
    "\n",
    "        st.write(\"### Best Recommendation based on F1 Score - Emissions:\")\n",
    "        st.write(f\"**Best Destination:** {best_destination}\")\n",
    "        \n",
    "\n",
    "run_streamlit_app_with_best_recommendation()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save the app code to a file\n",
    "with open(\"streamlit_app.py\", \"w\") as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "# Run the Streamlit app (in notebook environment)\n",
    "!streamlit run streamlit_app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Annecy\n",
       "1           Zuerich HB\n",
       "2    Rouen Rive Droite\n",
       "3          La Rochelle\n",
       "4             Grenoble\n",
       "Name: destination, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "models_path = 'app_models/'\n",
    "\n",
    "with open(os.path.join(models_path, \"agg_df_destination.pkl\"), \"rb\") as f:\n",
    "    agg_df_destination = pickle.load(f)\n",
    "agg_df_destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
